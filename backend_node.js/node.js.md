## Многопоточный сервер


Веб-приложения, написанные следуя клиент/серверной архитектуре, работают по следующей схеме — клиент запрашивает нужный ресурс у сервера и сервер отправляет ресурс в ответ. В этой схеме сервер, ответив на запрос, прерывает соединение.

Такая модель эффективна поскольку каждый запрос к серверу потребляет ресурсы (память, процессорное время и т.д.). Для того чтобы обрабатывать каждый последующий запрос от клиента, сервер должен завершить обработку предыдущего.

Значит ли это, что сервер может обрабатывать только один запрос за раз? Не совсем! Когда сервер получает новый запрос он создаёт отдельный **поток** для его обработки.

_Поток_, если простыми словами, это время и ресурсы, что CPU выделяет на выполнение небольшого блока инструкций. С учётом сказанного, сервер может обрабатывать несколько запросов одновременно, но только по одному на поток. Такая модель так же называться **thread-per-request model**.

Пользователь стучится на [http://yourstore.com/products](http://yourstore.com/products) и сервер рендерит HTML файл со всеми продуктами с базы данных в ответ. Совсем не сложно, да?

  

Но, что же происходит за кулисами?

  

- Когда пользователь стучится на `/products` особый метод или функция должна выполниться, что бы обработать запрос. Маленький кусочек кода (Ваш или фреймворка) анализирует URL-адрес запроса и ищет подходящий метод или функцию. **Поток работает**. 
- Теперь нужный метод или функция выполняться, так как и в первом пункте — **поток работает.
- Так как Вы хороший разработчик, Вы сохраняете все системные логи в файл, ну и конечно же, что бы быть уверенными, что роутер выполняет нужный метод/функцию — Вы так же логируете строку "Method X executing!!». Но всё это блокирующие операции ввода/вывода. **Поток ждёт**.
- Все логи сохранены и следующие строки функции выполняются. **Поток работает снова**. 
- Время обращаться к базе данных и получать все продукты – простой запрос, вроде `SELECT * FROM products`, выполняет свою работу, но угадайте что? Да-да, это блокирующая операция ввода/вывода. **Поток ждёт**. 
- Вы получили массив или список всех продуктов, но убедитесь, что Вы всё это залогировали. **Поток ждёт**. 
- Теперь у Вас есть все продукты и пришло время рендерить шаблон для будущей страницы, но перед этим Вам нужно их прочитать. **Поток ждёт**. 
- Движок рендеринга делает свою работу и шлёт ответ клиенту. **Поток работает снова**. 
- Поток свободен.

На сколько медленны операции ввода/вывода? Ну это зависит от конкретной. Давайте обратимся к таблице:

| **Операция**  | **Количество CPU тактов** |
| ------------- | ------------------------- |
| CPU Registers | 3 такта                   |
| L1 Cache      | 8 тактов                  |
| L2 Cache      | 12 тактов                 |
| RAM           | 150 тактов                |
| Disk          | 30,000,000 тактов         |
| Network       | 250,000,000 тактов        |

Операции сети и чтения с диска слишком медленные. Представьте сколько запросов или обращений к внешним API ваша система могла бы обработать за это время.

Подбивая итоги: операции ввода/вывода заставляют поток ждать и тратить ресурсы впустую.

### Проблема C10K

**Проблема C10k** (англ. _C10k; 10k connections_ — проблема 10 тысяч соединений)

В ранние 2000-е, серверные и клиентские машины были медленными. Проблема возникала при параллельной обработке 10 000 клиентских соединений к одной машине.

Но почему традиционная модель thread-per-request (поток на запрос) не могла решить эту проблему? Что ж, давайте используем немного математики.

Нативная реализация потоков выделяет больше 1 Мб памяти на поток, выходя из этого – для 10 тысяч потоков требуется 10 Гб оперативной памяти и это только для стека потоков. Да, и не забывайте, мы в начале 2000-х!!

В наши дни серверные и клиентские компьютеры работают быстрее и эффективней и почти любой язык программирования или фреймворк справляются с этой проблемой. Но фактически проблема не исчерпана. Для 10 миллионов клиентских соединений к одной машине проблема возвращается вновь (но теперь она [C10M Problem](http://c10m.robertgraham.com/p/manifesto.html)).


**JavaScript спасение?**

Node.js на самом деле решает проблему C10K… но как?!

Серверный JavaScript не был чем-то новым и необычным в начале 2000-х, на тот момент уже существовали реализации поверх JVM (java virtual machine) – RingoJS и AppEngineJS, что работали на модели thread-per-request.

Но если они не смогли решить проблему, тогда как Node.js смог?! Всё из-за того, что JavaScript **однопоточный**.

Пока файл считывается с диска, Node.js может обрабатывать другие запросы и даже считывать файл снова и всё это в одном потоке… но как?!

**Цикл событий**

**Цикл событий** — это магия, которая происходит внутри Node.js. Это буквально бесконечный цикл и на самом деле один поток.

**Libuv** — C библиотека которая реализует этот паттерн и является частью ядра Node.js. Вы можете узнать больше о libuv [здесь](https://nikhilm.github.io/uvbook/introduction.html).

Цикл событий имеет 6 фаз, каждое исполнение всех 6 фаз называют **tick**-ом.

- **timers**: в этой фазе выполняются коллбэки, запланированные методами `setTimeout()` и `setInterval()`;
- **pending callbacks**: выполняются почти все коллбэки, за исключением событий `close`, таймеров и `setImmediate()`;
- **idle, prepare**: используется только для внутренних целей;
- **poll**: ответственен за получение новых событий ввода/вывода. Node.js может блокироваться на этом этапе;
- **check**: коллбэки, вызванные методом `setImmediate()`, выполняються на этом этапе;
- **close callbacks**: например, `socket.on('close', ...)`;

Хорошо, есть только один поток, и этот поток и есть цикл событий, но тогда кто выполняет все операции ввода/вывода?

Обратите внимание!!!  
Когда циклу событий нужно выполнить операцию ввода/вывода он использует поток ОС с тредпула (thread pool), а когда задача выполнена, коллбэк ставится в очередь во время фазы _pending callbacks_.

Предположим, к нам стучатся 3 клиента и пытаются получить доступ к нашему не блокирующемуся вводом/выводом API:

- Первый запрашивает 5 простых чисел каждую секунду.
- Второй запрашивает 1000 простых чисел каждую секунду
- Третий запрашивает 10 000 000 000 простых чисел, но...

Когда третий клиент шлёт запрос – главный поток блокируется и это главный признак проблемы **CPU-ёмких задач**. Когда главный поток занят исполнением «тяжёлой» задачи он становится недоступен для других задач.

Но как насчёт libuv? Если Вы помните, эта библиотека помогает Node.js исполнять операции ввода/вывода с помощью потоков ОС избегая блокировки главного потока и Вы абсолютно правы, это решение нашей проблемы, но для того, что бы это стало возможным, наш модуль должен быть написан на языке C++, что бы libuv могла с ним работать.

К счастью, начиная с v10.5 в Node.js добавлен нативный модуль **Worker Threads**.

### Воркеры и их потоки

Как говорит нам [документация](https://nodejs.org/api/worker_threads.html):

> Воркеры полезны для выполнения CPU-ёмких JavaScript операций; не используйте их для операций ввода/вывода, уже встроенные в Node.js механизмы более эффективно справляются с такими задачами, чем Worker thread.

В файле `index-workerthreads.js` при каждом запросе на `/primes` создаётся экземпляр класса `Worker` (с нативного модуля `worker_threads`) для выгрузки и исполнения файла `primes-workerthreads.js` в поток воркера. Когда список простых чисел просчитан и готов, инициируется событие `message` – результат попадает в главный поток из-за того, что у воркера не осталось работы он также инициирует событие `exit`, позволяя основному потоку отправлять данные клиенту.

`primes-workerthreads.js` изменён немного. Он импортирует `workerData` (это копия параметров, переданных с основного потока) и `parentPort` через который результат работы воркера передаётся назад в главный поток.


[оригинал](https://habr.com/ru/articles/460661/)